Section 1: Theory Questions [25 points] 

1.1 In your own words, what does the role of a data scientist involve? 
- The role of a data scientist involves collecting, cleaning and analysing data using advanced statistical techniques and machine learning algorithms and outputting the results in graphs and tables to show patterns, trends and correlations in the data.

1.2 What is an outlier? Here we expect to see the following: 

a. Definition
– An outlier is a data point which is considered as an anomaly as it is either significantly higher or lower than the rest of the data points.

b. Examples 
– An example of an outlier could be in a dataset of house prices, where all the houses in an area range between £100,000 and £500,000, but you have a house which has a value of £1,500,000. This would be considered an outlier as the house price is significantly higher than all the other houses in the area. This could be a genuine outlier, or it could be an input error. Another example of an outlier is where you have a list of staff salaries and there is a member of staff who has a significantly higher salary than the rest of the staff. This could be a manager or owner of the business and would be relevant to the dataset.

c. Should outliers always be removed? Why? 
– Outliers should only be removed when it is deemed necessary to keep the integrity and accuracy of the dataset. Outliers can be very informative to a dataset and may give valuable insights to the data.

d. What are other possible issues that you can find in a dataset? 
- Other possible issues within a dataset can be incomplete, missing or NaN values. This could be where the information has not been entered by the user or has been entered incorrectly. Differences in data entry can also be an issue where someone may have entered ‘Male’ while someone else has entered ‘male’, meaning the data is not consistent and may show incorrectly when analysing the data. Duplicate values can also be an issue if someone has entered the same data more than once. This can skew results giving incorrect results.

1.3 Describe the concepts of data cleaning and data quality. Here we expect to see the following: 

a. What is data cleaning? 
- Data cleaning is the process of identifying and correcting errors, inconsistencies, and inaccuracies within a dataset. (reference: What is Data Cleaning? - GeeksforGeeks)

b. Why is data cleaning important? 
- Data cleaning is important as it improves the quality of the data making it easier to analyse. It also makes it easier for businesses and organisations to make informed decisions based on the data. 

c. What type of mistakes do we expect to commonly see in datasets? 
- Common mistakes in datasets are duplicate values where the same information has been entered more than once. Inconsistency in upper- and lower-case letters being used. Misspelling words/names leading to more unique values than there are. Missing values within the dataset where no data has been entered.

1.4 Discuss what is Unsupervised Learning - Clustering in Machine Learning using an example. Here we expect to see the following: 

a. Definition. 
- Unsupervised Learning is where the machine is given unlabelled input data and has to learn what the hidden structure is from the data. The machine then returns the structure, and the data is then classified according to that structure.
(Reference: CFG course materials)

b. When is it used? 
- Unsupervised Learning is used when you don’t know how to classify the data, and the machine is used to find the classifier for you.
(Reference: CFG course materials)

c. What is a possible real-world application of unsupervised learning? 
- One possible real-world application of unsupervised learning is a streaming platform monitoring your viewing habits and analysing the data to make recommendations to the viewer of other programmes or films they might like based on previous programmes/films watched. 

d. What are its main limitations?
- Limitations of unsupervised learning are that it would take longer for the machine to be trained. The results are often not at accurate as supervised learning. The output is heavily dependent on the model and the machine. It could cost more as it may require human intervention to understand the patterns and correlate them with the domain knowledge.
(Reference: Pros and Cons of Unsupervised Learning – Pythonista Planet)

1.5 Discuss what is Supervised Learning - Classification in Machine Learning using an example. Here we expect to see the following: 

a. Definition. 
- Supervised learning is where a person labels input data with a desired output. The machine is then given labelled training data and has to learn how to label the data before predicting the output for new data based on the learned model.
(Reference: CFG course materials)

b. When is it used? 
- Supervised Learning is used when you know how to classify data, but you want the machine to do it for you.
(Reference: CFG course materials)

c. What is a possible real-world application of supervised learning? 
- A possible real-world application of supervised learning is weather forecasting where the machine uses historical and recent weather data to predict further weather forecasts.

d. What data do we need for it? Is there any processing that needs to be done?
- For Supervised Learning, the machine is given training data to learn the model and then testing data to check if the model works. This is usually 80% training data and 20% testing data, but can be changed as required.  
